{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions to exercises\n",
    "\n",
    "**Not all solutions are complete. Some solutions required functions or variables that are already defined in the main notebooks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "We can also use ``LinearRegression`` to multi-feature data. Create a dataset that has 5 features. Calculate the coefficients and plot response vs the first feature, plot also the fitted line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_multi, y_multi = datasets.make_regression( n_samples=30, n_features=5, n_informative=5, random_state=0, noise=75)\n",
    "# just to have positive values only \n",
    "X_multi = X_multi + 3 \n",
    "y_multi = y_multi + 310\n",
    "\n",
    "regr_multi = LinearRegression()\n",
    "regr_multi.fit(X_multi, y_multi)\n",
    "print(regr_multi.intercept_, regr_multi.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Run a classification for Iris data available in ``datasets``. You can try to run model twice, first time using 2 features that have high correlation with output and second time with two less correlated features. You might also read and change parameters of the ``KNeighborsClassifier``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ir = iris.data\n",
    "y_ir = iris.target\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many classes you have\n",
    "np.unique(y_ir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot using only 2 features that has high correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_ir[:, 2], X_ir[:, 3], c=y_ir, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_ir[:,2:], y_ir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_iris(X_ir, y_ir, ind_x, ind_y):\n",
    "    x_min, x_max = X_ir[:, ind_x].min() - 0.2, X_ir[:, ind_x].max() + 0.2\n",
    "    y_min, y_max = X_ir[:, ind_y].min() - 0.2, X_ir[:, ind_y].max() + 0.2\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 50),\n",
    "                         np.linspace(y_min, y_max, 50))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure()\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X_ir[:, ind_x], X_ir[:, ind_y], c=y_ir, s=20)\n",
    "    \n",
    "plot_iris(X_ir, y_ir, ind_x=2, ind_y=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can check how the model would work if we chose the first tw features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_ir[:, 0], X_ir[:, 1], c=y_ir, s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that task will be harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_ir[:,:2], y_ir)\n",
    "\n",
    "plot_iris(X_ir, y_ir, ind_x=0, ind_y=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still the algorithm identified correctly most of the points. You can also try to change number of neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Use PCA for the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "\n",
    "n_components = 2\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_ir)\n",
    "\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "    \n",
    "for color, i, target_name in zip(colors, [0, 1, 2], iris.target_names):\n",
    "    plt.scatter(X_pca[y_ir == i, 0], X_pca[y_ir == i, 1],\n",
    "                color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Using ``make_data`` function generate a new dataset with different sample size. Calculate cross validation score using one od the [splitter methods available in scikit-learn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection). See how the scores differ with the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, y_new = make_data(N=50)\n",
    "\n",
    "X_new_tr, X_new_ts, y_new_tr, y_new_ts = train_test_split(X_new, y_new)\n",
    "\n",
    "poly2new = PolynomialRegression(2)\n",
    "poly2new.fit(X_new_tr, y_new_tr)\n",
    "plot_regr(X_new_tr, y_new_tr, poly2new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regr(X_new_ts, y_new_ts, poly2new, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "scores = cross_val_score(poly2new, X_new, y_new, cv=ShuffleSplit(n=y_new.shape[0]))\n",
    "print(\"Scores for regr: {}, mean score = {:03.2f}, std = {:03.2f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Change number of neigbors in ``KNeighborsClassifier`` model and run ``permutation_test_score`` again. Try a very large number, e.g. 300, can you explain the result? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "X_can = cancer.data\n",
    "y_can = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import permutation_test_score\n",
    "clf = KNeighborsClassifier(n_neighbors=300)\n",
    "score, permutation_scores, pvalue = permutation_test_score(\n",
    "    clf, X_can, y_can, scoring=\"accuracy\", cv=None, n_permutations=1000, n_jobs=1)\n",
    "print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(permutation_scores, 20, label='Permutation scores',\n",
    "         edgecolor='black', alpha=0.6)\n",
    "ylim = plt.ylim()\n",
    "\n",
    "plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "         label='Classification Score')\n",
    "plt.title(\"p_value = {:06.5f}\".format(pvalue))\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Run permutation test score for the model build for Iris data. You can use original data or after PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ir = KNeighborsClassifier()\n",
    "\n",
    "score_ir, permutation_scores_ir, pvalue_ir = permutation_test_score(\n",
    "    clf_ir, X_pca, y_ir, scoring=\"accuracy\", cv=None, n_permutations=1000, n_jobs=1)\n",
    "print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(permutation_scores_ir, 20, label='Permutation scores',\n",
    "         edgecolor='black', alpha=0.6)\n",
    "ylim = plt.ylim()\n",
    "\n",
    "plt.plot(2 * [score_ir], ylim, '--g', linewidth=3,\n",
    "         label='Classification Score')\n",
    "plt.title(\"p_value = {:06.5f}\".format(pvalue_ir))\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Validate the model using ``cross_val_score``. Try different kernels for SVM (you can read more [here](http://scikit-learn.org/stable/modules/svm.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit, LeaveOneOut\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "scores = cross_val_score(svc, fmri_masked_2lb, conditions_2lb, cv=LeaveOneOut(n=conditions.shape[0]))\n",
    "print(\"Scores: {}, mean score = {:03.2f}\".format(scores, scores.mean()))\n",
    "\n",
    "# you can also try a default kernel\n",
    "svc = SVC()\n",
    "scores = cross_val_score(svc, fmri_masked_2lb, conditions_2lb, cv=LeaveOneOut(n=conditions.shape[0]))\n",
    "print(\"Scores: {}, mean score = {:03.2f}\".format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "Check if KNeighborsClassifier would work for this dataset. Validate the model in the same way as SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_kn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf_kn, fmri_masked_2lb, conditions_2lb, cv=LeaveOneOut(n=conditions.shape[0]))\n",
    "print(\"Scores: {}, mean score = {:03.2f}\".format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "Try to run model using all conditions (except rest state). This is multiclass classification, try one-vs-all and one-vs-one strategies (can read more [here](https://en.wikipedia.org/wiki/Multiclass_classification))which one should be faster?\n",
    "Does the new model has as high score as the one with two conditions only? Which conditions is the easiest to identify by the model and which one is the hardest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing new masks\n",
    "conditions_new = conditions[conditions != b'rest']\n",
    "fmri_masked_new = fmri_masked[conditions != b'rest']\n",
    "fmri_masked_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running One-vs-one multiclass class. \n",
    "# note, that this will take a while... can you explain why?\n",
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit, LeaveOneOut\n",
    "svc_new_ovo = SVC(kernel='linear', decision_function_shape=\"ovo\")\n",
    "scores = cross_val_score(svc_new_ovo, fmri_masked_new, conditions_new, cv=LeaveOneOut(n=conditions_new.shape[0]))\n",
    "print(\"Scores: {}, mean score = {:03.2f}\".format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try one-vs-all now, it should be much faster\n",
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit, LeaveOneOut\n",
    "svc_new_ovr = SVC(kernel='linear', decision_function_shape=\"ovr\")\n",
    "scores = cross_val_score(svc_new_ovr, fmri_masked_new, conditions_new, cv=LeaveOneOut(n=conditions_new.shape[0]))\n",
    "print(\"Scores: {}, mean score = {:03.2f}\".format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets split manualy for two sets and see which conditions are easier to identify\n",
    "# since one vs all is much faster and  give the same reuslts, we will use this model \n",
    "fmri_new_tr, fmri_new_ts, cond_new_tr, cond_new_ts = train_test_split(fmri_masked_new, conditions_new)\n",
    "svc_new_ovr.fit(fmri_new_tr, cond_new_tr)\n",
    "cond_new_pred = svc_new_ovr.predict(fmri_new_ts)\n",
    "\n",
    "acc_cond = {}\n",
    "for cn in np.unique(cond_new_ts):\n",
    "    acc_cond[cn] = cond_new_pred[(cond_new_pred==cn) & (cond_new_ts==cn)].shape[0] / cond_new_ts[cond_new_ts==cn].shape[0]\n",
    "\n",
    "print(acc_cond)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
